{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4: CKY Algorithm and Dependency Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1: CKY Algorithm (30 points)\n",
    "\n",
    "In this section, you will implement the CKY algorithm for an unweighted CFG. See the starter code [cky.py](http://people.cs.umass.edu/~brenocon/inlp2017/hw4/cky.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 1.1 (8 points)\n",
    "Implement the acceptance version of CKY as ``cky_acceptance()``, which returns True if there is a ``S`` covering the entire sentence. Does it return True or False for the following sentences? Please ``pprint()`` the chart cells for each case as well. \n",
    "* the the\n",
    "* the table attacked a dog\n",
    "* the cat\n",
    "\n",
    "Hint: A simple way to implement the chart cells is by maintaining a list of nonterminals at the span. This list represents all possible nonterminals over that span. \n",
    "\n",
    "Hint: ``pprint()``ing the CKY chart cells may be useful for debugging.\n",
    "\n",
    "Hint: Python dictionaries allow tuples as keys. For example, ``d={}; d[(3,4)] = []``. A slight shortcut is that ``d[3,4]`` means the same thing as ``d[(3,4)]``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grammar rules in tuple form:\n",
      "[('S', ('NP', 'VP')),\n",
      " ('NP', ('Det', 'Noun')),\n",
      " ('VP', ('Verb', 'NP')),\n",
      " ('PP', ('Prep', 'NP')),\n",
      " ('NP', ('NP', 'PP')),\n",
      " ('VP', ('VP', 'PP'))]\n",
      "Rule parents indexed by children:\n",
      "{('Det', 'Noun'): ['NP'],\n",
      " ('NP', 'PP'): ['NP'],\n",
      " ('NP', 'VP'): ['S'],\n",
      " ('Prep', 'NP'): ['PP'],\n",
      " ('VP', 'PP'): ['VP'],\n",
      " ('Verb', 'NP'): ['VP']}\n"
     ]
    }
   ],
   "source": [
    "import cky\n",
    "from pprint import pprint\n",
    "print \"Grammar rules in tuple form:\"\n",
    "pprint(cky.grammar_rules)\n",
    "print \"Rule parents indexed by children:\"\n",
    "pprint(cky.possible_parents_for_children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the the\n",
      "False\n",
      "the table attacked a dog\n",
      "True\n",
      "the cat\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "#Print the result here\n",
    "import cky;reload(cky)\n",
    "print \"the the\"\n",
    "print cky.cky_acceptance([\"the\", \"the\"])\n",
    "print \"the table attacked a dog\"\n",
    "print cky.cky_acceptance([\"the\", \"table\", \"attacked\", \"a\", \"dog\"])\n",
    "print \"the cat\"\n",
    "print cky.cky_acceptance([\"the\", \"cat\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### Question 1.2 (15 points)\n",
    "Implement the parsing version of CKY, which returns one of the legal parses for the sentence (and returns None if there are none). If there are multiple real parses, we don’t care which one you print. Implement this as `cky_parse()`. You probably want to start by copying your `cky_acceptance()` answer and modifying it. Have it return the parse in the following format, using nested lists to represent the tree (this is a simple Python variant of the Lisp-style S-expression that’s usually used for this.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "['S',\n",
    "        [['NP', [['Det', 'the'], ['Noun', 'cat']]],\n",
    "         ['VP', [['Verb', 'attacked'], \n",
    "                 ['NP', [['Det', 'the'], ['Noun', 'food']]]]]]]\n",
    "                 ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the parses for the following sentences.  \n",
    "* the cat saw a dog\n",
    "* the cat saw a dog in a table\n",
    "* the cat with a table attacked the food  \n",
    "\n",
    "Hint: In the chart cells, you will now have to store backpointers as well. One way to do it is to store a list of tuples, each of which is  ``(nonterminal, splitpoint, leftchild nonterm, rightchild nonterm)``. For example, if the state ``('NP', 3, 'Det', 'Noun')`` is in the cell for span (2,4), that means this is a chart state of symbol NP, which came from a ``Det`` at position (2,3) and a Noun at position (3,4).\n",
    "\n",
    "Hint: It may be useful to use a recursive function for the backtrace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S',\n",
      " [['NP', [['Det', 'the'], ['Noun', 'cat']]],\n",
      "  ['VP', [['Verb', 'saw'], ['NP', [['Det', 'a'], ['Noun', 'dog']]]]]]]\n",
      "**************************************************\n",
      "['S',\n",
      " [['NP', [['Det', 'the'], ['Noun', 'cat']]],\n",
      "  ['VP',\n",
      "   [['Verb', 'saw'],\n",
      "    ['NP',\n",
      "     [['NP', [['Det', 'a'], ['Noun', 'dog']]],\n",
      "      ['PP', [['Prep', 'in'], ['NP', [['Det', 'a'], ['Noun', 'table']]]]]]]]]]]\n",
      "**************************************************\n",
      "['S',\n",
      " [['NP',\n",
      "   [['NP', [['Det', 'the'], ['Noun', 'cat']]],\n",
      "    ['PP', [['Prep', 'with'], ['NP', [['Det', 'a'], ['Noun', 'table']]]]]]],\n",
      "  ['VP', [['Verb', 'attacked'], ['NP', [['Det', 'the'], ['Noun', 'food']]]]]]]\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "# Output the results for each sentence.\n",
    "#TODO: Print out the parse tree for each of the three sentence\n",
    "\n",
    "pprint(cky.cky_parse(['the','cat','saw','a','dog']))\n",
    "print \"*\" * 50\n",
    "\n",
    "pprint(cky.cky_parse(['the','cat','saw','a','dog','in','a','table']))\n",
    "print \"*\" * 50\n",
    "\n",
    "pprint( cky.cky_parse(['the','cat','with','a','table','attacked','the','food']) )\n",
    "print \"*\" * 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 1.3 (7 points)\n",
    "Revise the grammar as follows.\n",
    "\n",
    "* Add four words to the lexicon: two verbs “attack” and “attacks”, and the nouns “cats” and “dogs”.\n",
    "* Revise the rules to enforce subject-verb agreement on number.\n",
    "\n",
    "The new grammar should accept and reject the following sentences. Please run your parser on these sentences and report the parse trees for the accepted ones. Also, describe how you changed the grammar, and why.\n",
    "\n",
    "ACCEPT: ``the cat attacks the dog``   \n",
    "REJECT: ``the cat attack the dog``  \n",
    "ACCEPT: ``the cats attack the dog``  \n",
    "REJECT: ``the cat with the food on a dog attack the dog``\n",
    "\n",
    "Hint: you will need to introduce new nonterminal symbols, and modify the currently existing ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revise:\n",
    "The new rule and lexicon is following. Classify nouns and verbs in single and plural form and make rules accordingly. The new parser confirms its correctness. None result means it's invalid.\n",
    "\n",
    "grammar_text = \"\"\"\n",
    "S -> NP VP\n",
    "S -> NP_s VP_s\n",
    "NP -> Det Noun\n",
    "VP -> Verb NP\n",
    "VP -> Verb NP_s\n",
    "VP_s -> Verb_s NP\n",
    "VP_s -> Verb_s NP_s\n",
    "NP_s ->Det Noun_s\n",
    "PP -> Prep NP\n",
    "NP -> NP PP\n",
    "VP -> VP PP\n",
    "\"\"\"\n",
    "\n",
    "lexicon = {\n",
    "    'Noun': set(['cats', 'dogs', 'table', 'food']),\n",
    "    'Noun_s' : set(['cat','dog']),\n",
    "    'Verb': set(['attacked', 'attack','saw', 'loved', 'hated']),\n",
    "    'Verb_s':set(['attacks']),\n",
    "    'Prep': set(['in', 'of', 'on', 'with']),\n",
    "    'Det': set(['the', 'a']),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S',\n",
      " [['NP_s', [['Det', 'the'], ['Noun_s', 'cat']]],\n",
      "  ['VP_s',\n",
      "   [['Verb_s', 'attacks'], ['NP_s', [['Det', 'the'], ['Noun_s', 'dog']]]]]]]\n",
      "**************************************************\n",
      "None\n",
      "**************************************************\n",
      "['S',\n",
      " [['NP', [['Det', 'the'], ['Noun', 'cats']]],\n",
      "  ['VP', [['Verb', 'attack'], ['NP_s', [['Det', 'the'], ['Noun_s', 'dog']]]]]]]\n",
      "**************************************************\n",
      "None\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "# Output the results for each sentence.\n",
    "#TODO: Print out the parse tree for each of the four sentence\n",
    "reload(cky)\n",
    "pprint( cky.cky_parse(['the','cat','attacks','the','dog']) )\n",
    "print \"*\" * 50\n",
    "#TODO: Print out the parse tree for each of the four sentence\n",
    "pprint( cky.cky_parse(['the','cat','attack','the','dog']) )\n",
    "print \"*\" * 50\n",
    "#TODO: Print out the parse tree for each of the four sentence\n",
    "pprint( cky.cky_parse(['the','cats','attack','the','dog']) )\n",
    "print \"*\" * 50\n",
    "#TODO: Print out the parse tree for each of the four sentence\n",
    "pprint( cky.cky_parse(['the','cat','with','the','food','on','a','dog','attack','the','dog']) )\n",
    "print \"*\" * 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2: Weighted CKY Algorithm (40 points)\n",
    "In this section you will implement the weighted CKY Algorithm for a Probabilistic CFG. You will have to make modifications to the existing algorithm to account for the probabilities and your parse function should output the most probable parse tree. \n",
    "Please write all your code in ``weighted_cky.py`` file for this section. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 2.1 (7 points)\n",
    "The CKY Algorithm requires the CFG to be in Chomsky Normal Form. Convert the following CFG into Chomsky Normal Form. (For the sake of uniformity, replace the leftmost pairs of non-terminals with new non-terminal)\n",
    "\n",
    "S -> Aux NP VP   \n",
    "S -> VP  \n",
    "VP -> Verb NP  \n",
    "VP -> VP PP  \n",
    "Verb -> book  \n",
    "Aux -> does  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer here\n",
    "    S -> Aux_NP VP \n",
    "    S -> VP \n",
    "    Aux_NP -> Aux NP \n",
    "    VP -> Verb NP \n",
    "    VP -> VP PP \n",
    "    Verb -> book \n",
    "    Aux -> does \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 2.2 (8 points)\n",
    "We will now implement a weighted CYK algorithm to parse a sentence and return the most probable parse tree. \n",
    "The grammar is defined in ``pcfg_grammar_original.txt``. As you can notice, some of the rules are not in CNF. \n",
    "Modify the ``pcfg_grammar_modified.txt`` file such that all the rules are in Chomsky Normal Form.\n",
    "(For the sake of uniformity, replace the leftmost pairs of non-terminals with new non-terminal)\n",
    "\n",
    "Note: When transforming the grammar to CNF, must set production probabilities to preserve the probability of derivations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Question 2.3 (5 points)\n",
    "Explain briefly what are the changes you made to convert the grammar into CNF Form. Why did you make these changes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer:\n",
    "1. conbine `Aux` and `NP`in `S -> Aux NP VP` as `Aux_NP`, a new non-termnal. add a new rule `Aux_NP -> Aux NP 1`\n",
    "This way the rules are binarized \n",
    "2. make 'Houston' to 'houston', 'I' to 'i' and 'NWA' to 'nwa' to differentiate the unary rules and lexicon terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 2.4 (8 points)\n",
    "Complete the ``populate_grammar_rules()`` function in the ``weighted_cky.py`` script. This function will have to read in the grammar rules from ``pcfg_grammar_modified.txt`` file and populate the `grammar_rules` and `lexicon` data structure. Additionally you would need to store the probability mapping in a suitable data structure. \n",
    "\n",
    "Hint: You can modify the starter code provided in cky.py for this task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grammar rules in tuple form:\n",
      "[('S', ('NP', 'VP')),\n",
      " ('S', ('Aux_NP', 'VP')),\n",
      " ('Aux_NP', ('Aux', 'NP')),\n",
      " ('S', 'VP'),\n",
      " ('NP', 'Pronoun'),\n",
      " ('NP', 'Proper-Noun'),\n",
      " ('NP', ('Det', 'Nominal')),\n",
      " ('Nominal', 'Noun'),\n",
      " ('Nominal', ('Nominal', 'Noun')),\n",
      " ('Nominal', ('Nominal', 'PP')),\n",
      " ('VP', 'Verb'),\n",
      " ('VP', ('Verb', 'NP')),\n",
      " ('VP', ('VP', 'PP')),\n",
      " ('PP', ('Prep', 'NP'))]\n",
      "probabilities\n",
      "{('Aux', 'does'): '1.0',\n",
      " ('Aux_NP', ('Aux', 'NP')): '1',\n",
      " ('Det', 'a'): '0.2',\n",
      " ('Det', 'that'): '0.1',\n",
      " ('Det', 'the'): '0.6',\n",
      " ('Det', 'this'): '0.1',\n",
      " ('NP', 'Pronoun'): '0.2',\n",
      " ('NP', 'Proper-Noun'): '0.2',\n",
      " ('NP', ('Det', 'Nominal')): '0.6',\n",
      " ('Nominal', 'Noun'): '0.3',\n",
      " ('Nominal', ('Nominal', 'Noun')): '0.2',\n",
      " ('Nominal', ('Nominal', 'PP')): '0.5',\n",
      " ('Noun', 'book'): '0.1',\n",
      " ('Noun', 'flight'): '0.5',\n",
      " ('Noun', 'meal'): '0.2',\n",
      " ('Noun', 'money'): '0.2',\n",
      " ('PP', ('Prep', 'NP')): '1.0',\n",
      " ('Prep', 'from'): '0.25',\n",
      " ('Prep', 'near'): '0.2',\n",
      " ('Prep', 'on'): '0.1',\n",
      " ('Prep', 'through'): '0.2',\n",
      " ('Prep', 'to'): '0.25',\n",
      " ('Pronoun', 'he'): '0.1',\n",
      " ('Pronoun', 'i'): '0.5',\n",
      " ('Pronoun', 'me'): '0.3',\n",
      " ('Pronoun', 'she'): '0.1',\n",
      " ('Proper-Noun', 'houston'): '0.8',\n",
      " ('Proper-Noun', 'nwa'): '0.20',\n",
      " ('S', 'VP'): '0.1',\n",
      " ('S', ('Aux_NP', 'VP')): '0.1',\n",
      " ('S', ('NP', 'VP')): '0.8',\n",
      " ('VP', 'Verb'): '0.2',\n",
      " ('VP', ('VP', 'PP')): '0.3',\n",
      " ('VP', ('Verb', 'NP')): '0.5',\n",
      " ('Verb', 'book'): '0.5',\n",
      " ('Verb', 'include'): '0.2',\n",
      " ('Verb', 'prefer'): '0.3'}\n",
      "Lexicon\n",
      "{'Aux': ['does'],\n",
      " 'Det': ['the', 'a', 'that', 'this'],\n",
      " 'Noun': ['book', 'flight', 'meal', 'money'],\n",
      " 'Prep': ['from', 'to', 'on', 'near', 'through'],\n",
      " 'Pronoun': ['i', 'he', 'she', 'me'],\n",
      " 'Proper-Noun': ['houston', 'nwa'],\n",
      " 'Verb': ['book', 'include', 'prefer']}\n"
     ]
    }
   ],
   "source": [
    "import weighted_cky as wcky;reload(wcky)\n",
    "\n",
    "wcky.populate_grammar_rules()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 2.5 (12 points)\n",
    "Implement the weighted parsing version of CKY, which returns the most probable legal parse for the sentence (and returns None if there are none). If there are multiple real parses, this function will always return the most probable parse i.e the one with maximum probability. \n",
    "Complete the ``pcky_parse()``.\n",
    "Print the parse tree and the probabilities for the following sentences:\n",
    "* book the flight through Houston\n",
    "* include this book\n",
    "* the the\n",
    "\n",
    "Hint: You can use the code in `cky_parse()` and modify it to accomodate probabilities and compute the most probable parse.   \n",
    "Note: The topmost cell should contain rules associated with the `S` non terminal, if any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "**************************************************\n",
      "[('S', 1.8e-05),\n",
      " [([('VP', 0.00018),\n",
      "    [(['Verb', 'include'], 0.2),\n",
      "     ([('NP', 0.0018),\n",
      "       [(['Det', 'this'], 0.1), (['Nominal', 'book'], 0.03)]],\n",
      "      0.0018)]],\n",
      "   0.00018)]]\n",
      "**************************************************\n",
      "[('S', 2.1600000000000007e-05),\n",
      " [([('VP', 0.00021600000000000005),\n",
      "    [([('VP', 0.0135),\n",
      "       [(['Verb', 'book'], 0.5),\n",
      "        ([('NP', 0.054),\n",
      "          [(['Det', 'the'], 0.6), (['Nominal', 'flight'], 0.15)]],\n",
      "         0.054)]],\n",
      "      0.0135),\n",
      "     ([('PP', 0.03200000000000001),\n",
      "       [(['Prep', 'through'], 0.2),\n",
      "        (['NP', 'Houston'], 0.16000000000000003)]],\n",
      "      0.03200000000000001)]],\n",
      "   0.00021600000000000005)]]\n"
     ]
    }
   ],
   "source": [
    "import weighted_cky as wcky;reload(wcky)\n",
    "from pprint import pprint\n",
    "# Output the results for each sentence.\n",
    "#TODO: Print out the parse tree for each of the three sentence\n",
    "pprint( wcky.pcky_parse(['the','the']) )\n",
    "print \"*\" * 50\n",
    "pprint( wcky.pcky_parse(['include','this','book']) )\n",
    "print \"*\" * 50\n",
    "pprint(wcky.pcky_parse(['book', 'the', 'flight', 'through', 'Houston']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3: Dependency parser output (30 points)\n",
    "\n",
    "You will conduct manual error analysis of [CoreNLP](https://stanfordnlp.github.io/CoreNLP/)'s dependency parser.\n",
    "\n",
    "Create an English sentence where the parser makes an error, and you know what the correct analysis ought to be, according to the Universal Dependencies grammatical standard.  You will want to play around with different sentences, look at their output, and check against the Universal Dependencies annotation standard.  The current version of CoreNLP outputs according to the \"UD version 1\" standard, so please use this page:\n",
    " * [UD v1 homepage](http://universaldependencies.org/docsv1/)\n",
    " * and in particular, the [UD v1 dependency relations list](http://universaldependencies.org/docsv1/u/dep/index.html)\n",
    "\n",
    "For quickly looking at things, their [online demo](http://corenlp.run/) may be useful.\n",
    "\n",
    "However, for this assignment, you need to run the parser to output in \"conllu\" format, which is human readable.  You need to download and run the parser for this.  (It requires Java.) Use version 3.8.0 (it should be the current version). You can it working in interactive mode so you can just type sentences into it on the terminal like this:\n",
    "\n",
    "```\n",
    "./corenlp.sh -annotators tokenize,ssplit,pos,lemma,depparse -outputFormat conllu \n",
    "[...]\n",
    "Entering interactive shell. Type q RETURN or EOF to quit.\n",
    "NLP> \n",
    "```\n",
    "\n",
    "For example then you can type\n",
    "```\n",
    "NLP> I saw a cat.\n",
    "1       I       I       _       PRP     _       2       nsubj   _       _\n",
    "2       saw     see     _       VBD     _       0       root    _       _\n",
    "3       a       a       _       DT      _       4       det     _       _\n",
    "4       cat     cat     _       NN      _       2       dobj    _       _\n",
    "5       .       .       _       .       _       2       punct   _       _\n",
    "```\n",
    "\n",
    "You can also use the `-inputFile` flag if you'd rather give it a whole file at once.\n",
    "\n",
    "As you can see in the parser documentation, the 7th and 8th columns describe the dependency edge for the word's parent (a.k.a governor): it has the index of its parent, and the edge label (a.k.a. the relation).  For example, this parse contains the dependency edge *nsubj(saw:2, I:1)* meaning that \"I\" is the subject of \"saw\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.1:** Once you've decided your sentence, please put the conllu-formatted parser output below in the markdown triple-quoted area.  Please be very careful where it goes since we will use a script to pull it out.\n",
    "    \n",
    "PARSE GOES BELOW HERE\n",
    "```\n",
    "1\tDo\tdo\t_\tVB\t_\t8\tcsubj\t_\t_\n",
    "2\tshow\tshow\t_\tNN\t_\t4\tcompound\t_\t_\n",
    "3\t1\t1\t_\tCD\t_\t4\tnummod\t_\t_\n",
    "4\texample\texample\t_\tNN\t_\t1\tdobj\t_\t_\n",
    "5\tof\tof\t_\tIN\t_\t7\tcase\t_\t_\n",
    "6\tthat\tthat\t_\tDT\t_\t7\tdet\t_\t_\n",
    "7\tNP\tnp\t_\tNN\t_\t4\tnmod\t_\t_\n",
    "8\tequals\tequal\t_\tVBZ\t_\t0\troot\t_\t_\n",
    "9\tP\tp\t_\tNN\t_\t8\tdobj\t_\t_\n",
    "\n",
    "```\n",
    "PARSE GOES ABOVE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.2:** Please describe the error you found.  Also give a citation and link to the relevant part of the UD documentation describing one of the relations that the parser predicted in error, or did something wrong with.               \n",
    "\n",
    "**`Answer` :**  \n",
    "\n",
    "`'Do'` has the dependency edge `'csubj'`(`'Do'`:1, `'equals'`:8), meaning the `'Do'` clause is the clause subject of `'equals'`.\n",
    "`'show'` has dependency edge `'compound'`(`'show'`:2,`'example'`:4), which is clearly incorrect. \n",
    "The CoreNLP could be incorrect in parsing the subjectless sentences(imperatives in this case) with ambiguities(`'show'` can be both verb and noun).  \n",
    "\n",
    "For citation and link, see section 3.6:\n",
    "https://catalog.ldc.upenn.edu/docs/LDC99T42/prsguid2.pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Question 3.3:** Please give correct that error in the parse .  Put your corrected parse, again in that conllu textual format, below.  You should take a copy of the output and manually change some of the 7th/8th dependency edge columns.\n",
    "\n",
    "PARSE GOES BELOW HERE\n",
    "```\n",
    "1\tDo\t    do\t    _\tVB\t_\t2\taux\t_\t_\n",
    "2\tshow\tshow\t_\tVB\t_\t0\troot_\t_\n",
    "3\t1\t    1\t    _\tCD\t_\t4\tnum\t_\t_\n",
    "4\texample\texample\t_\tNN\t_\t1\tdobj\t_\t_\n",
    "5\tof\t    of\t    _\tIN\t_\t6\tcase\t_\t_\n",
    "6\tthat\tthat\t_\tIN\t_\t8\tmark\t_\t_\n",
    "7\tNP\t    np\t    _\tNN\t_\t8\tnsubj\t_\t_\n",
    "8\tequals\tequal\t_\tVBZ\t_\t0\tccomp\t_\t_\n",
    "9\tP\t    p\t    _\tNN\t_\t8\tdobj\t_\t_\n",
    "\n",
    "```\n",
    "PARSE GOES ABOVE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.4:** Please describe your correction and why it solves the error.   \n",
    "\n",
    "**Answer : **\n",
    "\n",
    "I made *'Do'* as *'aux'* with dependency edge 2, *'show'* as root, *'that'* as *'mark'* with dependency edge 8. *'NP'* as *'nsubj'* with dependency edge 8.   \n",
    "This way, *'do'* is parsed as an aux verb of *'show'*, which is the verb, as it should be as we know it. *'that'* is corrected as a mark of object clause, which is what we know of.And the others simply follow\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
